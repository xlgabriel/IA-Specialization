{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch"
      ],
      "metadata": {
        "id": "NpFNVmx148OC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Integrantes:\n",
        "LEONARDO FABIO GRISALES HURTADO\n",
        "\n",
        "JORGE LUIS GUECHE MANQUILLO\n",
        "\n",
        "JORGE ANDRES JARAMILLO NEME \n",
        "\n",
        "JUAN STIVEN MOLINA GRAJALES\n",
        "\n",
        "EDGAR FERNANDO PAREDES BANGUERO"
      ],
      "metadata": {
        "id": "pSa8AOVk5EzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##¿Qué es PyTorch?\n",
        "PyTorch es una librería open source basada en Python, enfocada a la realización de cálculos numéricos mediante programación de tensores, lo que facilita su aplicación al desarrollo de aplicaciones de aprendizaje profundo. La sencillez de su interfaz, y su capacidad para ejecutarse en GPUs (lo que acelera el entrenamiento de los modelos), lo convierten en la opción más asequible para crear redes neuronales artificiales.\n",
        "\n",
        "Estas redes neuronales se han convertido, quizá, en la rama más prometedora de la inteligencia artificial, siendo la base de otras tecnologías como los sistemas de traducción automática, de reconocimiento de imágenes, facial, de voz.\n",
        "## ¿Por qué usar PyTorch? \n",
        "PyTorch dispone una interfaz muy sencilla para la creación de redes neuronales pese a trabajar de forma directa con tensores sin la necesidad de una librería a un nivel superior como pueda ser Keras para Theano o Tensorflow.\n",
        "\n",
        "PyTorch dispone de soporte para su ejecución en tarjetas gráficas (GPU), utiliza internamente CUDA, una API que conecta la CPU con la GPU que ha sido desarrollado por NVIDIA\n",
        "##¿Qué se puede usar con PyTorch?\n",
        "-Matrices.\n",
        "\n",
        "-Algebra lineal.\n",
        "\n",
        "-Creación de una red de feedforward.\n",
        "\n",
        "Torch es uno de los frameworks de Deep Learning más populares en el mundo, dominando gran parte de la comunidad de investigación en los últimos años (solo recientemente rivalizado con los principales frameworks patrocinados por Google, Tensorflow  y Keras)\n",
        "##Aplicaciones\n",
        "Originalmente desarrollado por FAER (siglas de Facebook AI Research), PyTorch ha sido a su vez una pieza fundamental en el desarrollo de relevantes aplicaciones de inteligencia artificial, como el Autopilot de Tesla y el Pyro de Uber.\n",
        "\n",
        "Con el tiempo, y gracias a una facilidad de uso no reñida con su uso en el ámbito industrial, PyTorch se ha convertido en uno de los frameworks de Deep Learning más populares del mundo, al que solo le hacen sombra TensorFlow y Keras, ambos respaldados por el patrocinio de Google.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FykGqBtZy-xG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RK4A8plgALou"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v3iRCRUTGeu"
      },
      "source": [
        "## Importando PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1VxEOik46Y4i",
        "outputId": "f3141076-29bc-4600-c1c3-1586b1fe2292"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-33BKR16iWc"
      },
      "source": [
        "## Introducción a los Tensores \n",
        "\n",
        "Ahora que tenemos PyTorch importado, es hora de aprender acerca de los tensores.\n",
        "\n",
        "Los tensores son el bloque de construcción fundamental del aprendizaje automático.\n",
        "\n",
        "Su función es representar datos de forma numérica.\n",
        "\n",
        "Por ejemplo, se puede representar una imagen como un tensor con forma `[3, 224, 224]` lo que significaría `[colour_channels, height, width]`, como la imagen tiene `3` canales de color (red, green, blue), una altura de `224` píxeles y una anchura de `224` píxeles.\n",
        "\n",
        "![example of going from an input image to a tensor representation of the image, image gets broken down into 3 colour channels as well as numbers to represent the height and width](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
        "\n",
        "En lenguaje tensorial (el utilizado para describir los tensores), el tensor tendría tres dimensiones, una para `colour_channels`, `height` y `width`.\n",
        "\n",
        "Los Tensores de PyTorch son similares a los Vectores de NumPy, pero también se pueden operar en una GPU de Nvidia compatible con CUDA. PyTorch soporta varios subtipos de Tensores.\n",
        "\n",
        "Parece haber 4 tipos principales de tensores en PyTorch: tensores de Byte, Float, Double y Long. Cada tipo de tensor corresponde al tipo de número (y más importante, el tamaño / indicación del número) contenido en cada lugar de la matriz. Entonces, si un Tensor de 1-d es una “lista de números”, un Tensor de Flotación de 1-d es una lista de flotadores . Como regla general, para peso matries usamos FloatTensors. Para las matrices de datos, es probable que usemos FloatTensors (para entradas con valores reales) o Long Tensors (para enteros).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modulos"
      ],
      "metadata": {
        "id": "QxNK8DpO-wWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Autograd module\n",
        "PyTorch utiliza un método llamado diferenciación Automática. Unos registrador registra lo que las operaciones que se han hecho, y luego las reproduce hacia atrás para calcular los gradientes. Este método es especialmente potente cuando se están construyendo redes neuronales para ahorrar tiempo en una época en la que calcular la diferenciación de los parámetros es un paso adelante.\n",
        "###Optim module\n",
        "torch.optim es un módulo que implementa varios algoritmos de optimización que se utilizan para construir redes neuronales. La mayoría de los métodos comúnmente usados ya son compatibles, por lo que no hay ninguna necesidad de crearlos desde cero\n",
        "###Nn module\n",
        "PyTorch Autograd hace que sea fácil definir gráficos computacionales y coger distintos grados, pero Raw Autograd puede ser un nivel demasiado bajo para definir redes neuronales complejas. Por esto es por lo que se creó el módulo nn, para ayudar a crear redes neuronales más complejas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OJUajJza-5oO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgYkrRCRec0r"
      },
      "source": [
        "##Flujo de trabajo en Pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51Ug7Ug123Ip"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01_a_pytorch_workflow.png\" width=900 alt=\"a pytorch workflow flowchat\"/>\n",
        "\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **1. Getting data ready** | Data can be almost anything but to get started we're going to create a simple straight line |\n",
        "| **2. Building a model** | Here we'll create a model to learn patterns in the data, we'll also choose a **loss function**, **optimizer** and build a **training loop**. | \n",
        "| **3. Fitting the model to data (training)** | We've got data and a model, now let's let the model (try to) find patterns in the (**training**) data. |\n",
        "| **4. Making predictions and evaluating a model (inference)** | Our model's found patterns in the data, let's compare its findings to the actual (**testing**) data. |\n",
        "| **5. Saving and loading a model** | You may want to use your model elsewhere, or come back to it later, here we'll cover that. |\n",
        "| **6. Putting it all together** | Let's take all of the above and combine it. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeAITvLXec06"
      },
      "source": [
        "## Ejemplo: Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8hZ3CWhAIpUF",
        "outputId": "60b4e98b-8d83-4573-cbe2-131df190b223"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import PyTorch and matplotlib\n",
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT-krbNMIw0d"
      },
      "source": [
        "Now let's start making our code device agnostic by setting `device=\"cuda\"` if it's available, otherwise it'll default to `device=\"cpu\"`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx2Zpb5sec06",
        "outputId": "88323445-9070-4b3d-a62a-3d924d8d6898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1t0Ek0GJq6T"
      },
      "source": [
        "If you've got access to a GPU, the above should've printed out:\n",
        "\n",
        "```\n",
        "Using device: cuda\n",
        "```\n",
        "Otherwise, you'll be using a CPU for the following computations. This is fine for our small dataset but it will take longer for larger datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmilLp3Vec07"
      },
      "source": [
        "### 6.1 Data\n",
        "\n",
        "Let's create some data just like before.\n",
        "\n",
        "First, we'll hard-code some `weight` and `bias` values.\n",
        "\n",
        "Then we'll make a range of numbers between 0 and 1, these will be our `X` values.\n",
        "\n",
        "Finally, we'll use the `X` values, as well as the `weight` and `bias` values to create `y` using the linear regression formula (`y = weight * X + bias`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJqgDWUfec07",
        "outputId": "62d07f54-bb59-4327-a153-79be9ada83d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create weight and bias\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create range values\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "# Create X and y (features and labels)\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1) # without unsqueeze, errors will happen later on (shapes within linear layers)\n",
        "y = weight * X + bias \n",
        "X[:10], y[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaar6rDGLGaQ"
      },
      "source": [
        "Wonderful!\n",
        "\n",
        "Now we've got some data, let's split it into training and test sets.\n",
        "\n",
        "We'll use an 80/20 split with 80% training data and 20% testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQoo65evec07",
        "outputId": "80c3f9b7-4d1d-4aef-fc19-7abceaf93eb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split data\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INW8-McyLeFE"
      },
      "source": [
        "Excellent, let's visualize them to make sure they look okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "gxhc0zCdec07",
        "outputId": "cc3cb921-0d25-4cec-d681-da102547bdb9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGbCAYAAADgEhWsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm+ElEQVR4nO3dfXRUhb3u8eeXBARBIJQAEhRQUUEECxHLWVVA60EFFuXaLkCroFbDBc6SdXzB6hGL2q622lq95tRgD6W+VG0VWwoc0OMVQSuSgEINQU9EhCAlCb0LBVshye/+MTlpEpLMhD3v8/2sNSvZLzPzIxv0yZ49z5i7CwAAACcmK9EDAAAApDLCFAAAQACEKQAAgAAIUwAAAAEQpgAAAALISdQT9+nTxwcPHpyopwcAAIjYli1batw9r7VtCQtTgwcPVmlpaaKeHgAAIGJm9klb23iZDwAAIADCFAAAQACEKQAAgAAIUwAAAAEQpgAAAAII+24+M1smaYqkKncf0cp2k/SopKskfSFpjrtvDTrYZ599pqqqKh07dizoQyEDdOvWTQMHDlRWFr8fAADiK5JqhOWSHpf0VBvbr5Q0tOF2kaRfNHw9YZ999pkOHDig/Px8de3aVaG8BrSuvr5e+/btU01Njfr27ZvocQAAGSbsr/HuvkHSX9vZZZqkpzxkk6ReZnZqkKGqqqqUn5+vk08+mSCFsLKystSvXz8dOnQo0aMAADJQNF4TyZe0t8lyZcO6E3bs2DF17do10FDILJ06dVJtbW2ixwAAZKBohKnWTh15qzua3WJmpWZWWl1d3f6DckYKHcDfFwBAokQjTFVKOq3J8kBJn7a2o7svdfcCdy/Iy2v1420AAABSSjTC1EpJ11vI1yQdcvf9UXhcAACApBc2TJnZc5LelnSOmVWa2U1mNtfM5jbsskbSLkkVkp6UNC9m02agOXPmaMqUKR26z4QJE7RgwYIYTdS+BQsWaMKECQl5bgAAEiFsNYK7zwqz3SXNj9pEKSrcNTuzZ8/W8uXLO/y4jz76qEI/4sitWLFCnTp16vBzJcLu3bs1ZMgQlZSUqKCgINHjAADQYZH0TCEC+/f/45XNVatW6eabb262ruW7E48dOxZR4OnZs2eHZ+ndu3eH7wMAAE4MddFR0r9//8Zbr169mq37+9//rl69eum5557TpZdeqq5du6q4uFgHDx7UrFmzNHDgQHXt2lXnnXeefvWrXzV73JYv802YMEHz5s3T3XffrT59+qhv3766/fbbVV9f32yfpi/zDR48WA8++KAKCwvVo0cPDRw4UA899FCz5/nwww81fvx4denSReecc47WrFmj7t27t3s2ra6uTrfffrtyc3OVm5urhQsXqq6urtk+a9eu1cUXX6zc3Fz17t1bkyZNUnl5eeP2IUOGSJIuvPBCmVnjS4QlJSX653/+Z/Xp00c9evTQ17/+db399tvhDwQAIKPMXz1fOffnaP7qxL1IRpiKo+9973uaN2+eduzYoW9+85v6+9//rtGjR2vVqlUqKyvTrbfeqsLCQr322mvtPs6zzz6rnJwc/elPf9Ljjz+un//853rhhRfavc8jjzyi888/X1u3btWiRYt05513NoaT+vp6TZ8+XTk5Odq0aZOWL1+uJUuW6Msvv2z3MX/605/qySefVHFxsd5++23V1dXp2WefbbbPkSNHtHDhQm3evFnr169Xz549NXXqVB09elSStHnzZkmh0LV//36tWLFCkvT555/ruuuu08aNG7V582ZdcMEFuuqqq1RTU9PuTACAzFK8pVh1XqfiLcWJG8LdE3IbM2aMt2XHjh1tbuuoefPcs7NDX+Pld7/7nYd+tCEff/yxS/KHH3447H1nzJjhN910U+Py7NmzffLkyY3L48eP96997WvN7vONb3yj2X3Gjx/v8+fPb1weNGiQz5w5s9l9zjrrLH/ggQfc3X3t2rWenZ3tlZWVjdvfeustl+S/+tWv2pz11FNP9QcffLBxua6uzocOHerjx49v8z6HDx/2rKws37hxo7v/42dTUlLS5n3c3evr671///7+9NNPt7lPNP/eAABSw7xV8zx7SbbPWxXb/9FLKvU2Mk3an5kqLpbq6kJfE63lBdZ1dXX6wQ9+oJEjR+orX/mKunfvrhUrVmjPnj3tPs7IkSObLQ8YMEBVVVUnfJ+dO3dqwIABys//R3H9hRde2O6HBh86dEj79+/XuHHjGtdlZWXpoouafyzjRx99pGuuuUZnnnmmevTooX79+qm+vj7sn7GqqkqFhYU6++yz1bNnT51yyimqqqoKez8AQGYpmlyk2sW1KppclLAZ0v4C9MLCUJAqLEz0JFK3bt2aLT/88MP66U9/qkcffVTnn3++unfvrrvvvjtsMGp54bqZNbtmqqP3cfeYNYhPnTpV+fn5Ki4uVn5+vnJycjR8+PDGl/naMnv2bB04cECPPPKIBg8erJNOOkmXXXZZ2PsBABBvaR+miopCt2T05ptvaurUqbruuuskhULNhx9+2HgBe7wMGzZM+/bt06effqoBAwZIkkpLS9sNaD179tSpp56qTZs26dJLL5UUmn/z5s069dTQ51wfPHhQ5eXlKioq0sSJEyVJW7dubfYZep07d5ak4y5cf/PNN/XYY49p8uTJkqQDBw40e3ckAADJIu1f5ktmZ599tl577TW9+eab2rlzpxYsWKCPP/447nNcfvnlOuecczR79mxt27ZNmzZt0r/+678qJyen3TNWt956q37yk5/oxRdf1AcffKCFCxc2Czy5ubnq06ePnnzySVVUVOiNN97Q3LlzlZPzjwzft29fde3aVevWrdOBAwd06NAhSaGfzTPPPKMdO3aopKREM2fObAxeAAAkE8JUAv3bv/2bxo4dqyuvvFKXXHKJunXrpmuvvTbuc2RlZenll1/Wl19+qbFjx2r27Nm65557ZGbq0qVLm/e77bbbdMMNN+i73/2uLrroItXX1zebPysrSy+88IK2b9+uESNGaP78+XrggQd00kknNe6Tk5Ojxx57TL/85S81YMAATZs2TZK0bNkyHT58WGPGjNHMmTN14403avDgwTH7GQAAkkcy1B10hHkH27WjpaCgwEtLS1vdVl5ermHDhsV5IjS1bds2XXDBBSotLdWYMWMSPU5E+HsDAOkh5/4c1Xmdsi1btYtrw98hDsxsi7u3+lEdnJmCJOnll1/WK6+8oo8//livv/665syZo1GjRmn06NGJHg0AkGEKxxQq27JVOCYJ3j0WgbS/AB2R+fzzz7Vo0SLt3btXubm5mjBhgh555JGYvcsPAIC2FE0uSmjVQUcRpiBJuv7663X99dcnegwAAFIOL/MBAAAEQJgCAAAIgDAFAADiItUqDyJFmAIAAHFRvKVYdV6n4i1J8IG5UUSYAgAAcZFqlQeR4t18AAAgLlKt8iBSnJlKYYMHD9bDDz+ckOeeMmWK5syZk5DnBgAgmRCmosTM2r0FCR7f//73NWLEiOPWl5SUaN68eQGmjp/169fLzFRTU5PoUQAAiCpe5ouS/fv3N36/atUq3Xzzzc3Wde3aNerPmZeXF/XHBAAAHcOZqSjp379/461Xr17HrduwYYPGjBmjLl26aMiQIbrnnnt09OjRxvuvWLFCI0eOVNeuXdW7d2+NHz9eBw4c0PLly7VkyRKVlZU1nuVavny5pONf5jMzLV26VN/+9rfVrVs3nXHGGXrmmWeazfnOO+9o9OjR6tKli7761a9qzZo1MjOtX7++zT/bF198oTlz5qh79+7q16+ffvjDHx63zzPPPKMLL7xQp5xyivr27atvf/vb2rdvnyRp9+7dmjhxoqRQAGx6pm7t2rW6+OKLlZubq969e2vSpEkqLy/v6I8fAJBA6Vp5ECnCVBysW7dO1157rRYsWKCysjItW7ZML774ou6++25J0l/+8hfNnDlTs2fPVnl5uTZs2KDrrrtOkjRjxgzddtttOuecc7R//37t379fM2bMaPO57r//fk2bNk3btm3TjBkzdOONN+qTTz6RJB0+fFhTpkzRueeeqy1btugnP/mJ7rjjjrDz33777Xr11Vf10ksv6bXXXtO7776rDRs2NNvn6NGjWrJkibZt26ZVq1appqZGs2bNkiSddtppeumllyRJZWVl2r9/vx599FFJ0pEjR7Rw4UJt3rxZ69evV8+ePTV16tRmQRMAkNzStfIgYu6ekNuYMWO8LTt27GhzW0fNWzXPs5dk+7xV86L2mOH87ne/89CPNuTiiy/2+++/v9k+L7/8snfr1s3r6+t9y5YtLsl3797d6uPdd999ft555x23ftCgQf7QQw81Lkvyu+66q3H52LFj3rVrV3/66afd3f2JJ57w3Nxc/+KLLxr3efbZZ12Sv/76660+9+eff+6dO3f2Z555ptm6nj17+uzZs9v8GZSXl7sk37t3r7u7v/766y7Jq6ur27yPu/vhw4c9KyvLN27c2O5+rYnm3xsAQOQS8f/aeJNU6m1kmrQ/M5UMaXnLli36wQ9+oO7duzferrnmGh05ckR/+ctfNGrUKH3jG9/QiBEjdPXVV+sXv/iFqqurT+i5Ro4c2fh9Tk6O8vLyVFVVJUnauXOnRowY0ez6rYsuuqjdx/voo4909OhRjRs3rnFd9+7ddf755zfbb+vWrZo2bZoGDRqkU045RQUFBZKkPXv2hH38a665RmeeeaZ69Oihfv36qb6+Puz9AADJo2hykWoX16Zl7UEk0j5MJUNBWH19ve677z699957jbft27frv//7v5WXl6fs7Gy98soreuWVVzRy5Ej9x3/8h4YOHapt27Z1+Lk6derUbNnMVF9fLyl0FtLMOvR4oTDeviNHjmjSpEk6+eST9fTTT6ukpERr166VpLAv102dOlXV1dUqLi7WO++8o3fffVc5OTm8zAcASBlp/26+ZCgIGz16tHbu3KmzzjqrzX3MTOPGjdO4ceO0ePFinXfeeXrhhRc0atQode7cWXV1dYHnGDZsmJ566in97W9/azw7tXnz5nbvc9ZZZ6lTp07atGmTzjjjDEmh8PT+++/rzDPPlBQ641VTU6Mf/vCHGjJkiKTQBfVNde7cWZKa/TkOHjyo8vJyFRUVNV6gvnXrVtXW1gb+swIAEC9pf2YqGSxevFi/+c1vtHjxYr3//vvauXOnXnzxRd15552SpE2bNunBBx9USUmJ9uzZo5UrV2rv3r0aPny4pNC79j755BNt3bpVNTU1+vLLL09ojmuvvVbZ2dm6+eabtWPHDv3Xf/1X4zvz2jpj1b17d910001atGiRXn31VZWVlenGG29sFopOP/10nXTSSXr88ce1a9curV69Wvfee2+zxxk0aJDMTKtXr1Z1dbUOHz6s3Nxc9enTR08++aQqKir0xhtvaO7cucrJSfuMDwBII4SpOJg0aZJWr16t119/XWPHjtXYsWP1ox/9SKeffrokqWfPnnrrrbc0ZcoUDR06VLfddpvuvfdefec735EkXX311brqqqt02WWXKS8vT88999wJzdG9e3f98Y9/VFlZmb761a/qjjvu0Pe//31JUpcuXdq838MPP6yJEydq+vTpmjhxokaMGKFLLrmkcXteXp5+/etf6/e//72GDx+uJUuW6Gc/+1mzx8jPz9eSJUt0zz33qF+/flqwYIGysrL0wgsvaPv27RoxYoTmz5+vBx54QCeddNIJ/fkAANGT6XUHHWGRXBMTCwUFBV5aWtrqtvLycg0bNizOE2WmP/zhD5o+fbqqqqrUp0+fRI8TCH9vACB6cu7PUZ3XKduyVbuYyy/MbIu7F7S2jTNTGebXv/61Nm7cqN27d2vVqlVauHChpk6dmvJBCgAQXcnwBq5UwcUpGebAgQO67777tH//fvXv31+TJ0/Wj3/840SPBQBIMsnwBq5UQZjKMHfeeWfjhe8AACA4XuYDAAAIIGnD1P8UTQKRSNQbKQAASMow1a1bN+3bt09Hjx7lf5IIy9118ODBdusdAAAhVB5EX1JWI9TX16umpkaHDh2iDRsR6dKliwYOHHjcx+kAAJqj8uDEtFeNkJQXoGdlZalv377q27dvokcBACCtFI4pVPGWYioPoigpz0wBAAAkE0o7AQAAYoQwBQAAEEBEYcrMrjCzD8yswszuamV7rpm9bGbbzWyzmY2I/qgAAADJJ2yYMrNsSUWSrpQ0XNIsMxveYre7Jb3n7iMlXS/p0WgPCgAA2kblQeJEcmZqrKQKd9/l7kclPS9pWot9hkt6TZLcfaekwWbWL6qTAgCANhVvKVad16l4S3GiR8k4kYSpfEl7myxXNqxrapuk/yVJZjZW0iBJA1s+kJndYmalZlZaXV19YhMDAIDjFI4pVLZlU3mQAJH0TFkr61r2KfxI0qNm9p6kP0t6V9JxTWDuvlTSUilUjdChSQEAQJuKJhepaHJRosfISJGEqUpJpzVZHijp06Y7uPtnkm6QJDMzSR833AAAANJaJC/zlUgaamZDzKyzpJmSVjbdwcx6NWyTpO9K2tAQsAAAANJa2DNT7l5rZgskrZOULWmZu5eZ2dyG7U9IGibpKTOrk7RD0k0xnBkAACBpRPTZfO6+RtKaFuueaPL925KGRnc0AAAy2/zV8xs/R4/roZIXDegAACQp6g5SA2EKAIAkRd1BajD3xDQUFBQUeGlpaUKeGwAAoCPMbIu7F7S2jTNTAAAAARCmAAAAAiBMAQAABECYAgAgzuavnq+c+3M0f/X8RI+CKCBMAQAQZ1QepBfCFAAAcUblQXqhGgEAACAMqhEAAABihDAFAAAQAGEKAAAgAMIUAABRQuVBZiJMAQAQJVQeZCbCFAAAUULlQWaiGgEAACAMqhEAAABihDAFAAAQAGEKAAAgAMIUAADtmD9fyskJfQVaQ5gCAKAdxcVSXV3oK9AawhQAAO0oLJSys0NfgdZQjQAAABAG1QgAAAAxQpgCAAAIgDAFAAAQAGEKAJCRqDxAtBCmAAAZicoDRAthCgCQkag8QLRQjQAAABAG1QgAAAAxQpgCAAAIgDAFAAAQAGEKAJBWqDxAvBGmAABphcoDxBthCgCQVqg8QLxRjQAAABAG1QgAAAAxQpgCAAAIgDAFAAAQQERhysyuMLMPzKzCzO5qZXtPM/ujmW0zszIzuyH6owIAMhV1B0hmYS9AN7NsSR9KulxSpaQSSbPcfUeTfe6W1NPdF5lZnqQPJPV396NtPS4XoAMAIpWTE6o7yM6WamsTPQ0yUdAL0MdKqnD3XQ3h6HlJ01rs45JOMTOT1F3SXyXx1x0AEBXUHSCZRRKm8iXtbbJc2bCuqcclDZP0qaQ/S7rV3etbPpCZ3WJmpWZWWl1dfYIjAwAyTVFR6IxUUVGiJwGOF0mYslbWtXxtcJKk9yQNkHSBpMfNrMdxd3Jf6u4F7l6Ql5fXwVEBAACSTyRhqlLSaU2WByp0BqqpGySt8JAKSR9LOjc6IwIAACSvSMJUiaShZjbEzDpLmilpZYt99ki6TJLMrJ+kcyTtiuagAAAAyShsmHL3WkkLJK2TVC7pt+5eZmZzzWxuw24PSPonM/uzpNckLXL3mlgNDQBID1QeIB3w2XwAgISh8gCpgs/mAwAkJSoPkA44MwUAABAGZ6YAAABihDAFAAAQAGEKAAAgAMIUACDqqDxAJiFMAQCirrg4VHlQXJzoSYDYI0wBAKKOygNkEqoRAAAAwqAaAQAAIEYIUwAAAAEQpgAAAAIgTAEAAARAmAIARITuKKB1hCkAQETojgJaR5gCAESE7iigdfRMAQAAhEHPFAAAQIwQpgAAAAIgTAEAAARAmAKADEflARAMYQoAMhyVB0AwhCkAyHBUHgDBUI0AAAAQBtUIAAAAMUKYAgAACIAwBQAAEABhCgDSEHUHQPwQpgAgDVF3AMQPYQoA0hB1B0D8UI0AAAAQBtUIAAAAMUKYAgAACIAwBQAAEABhCgBSCJUHQPIhTAFACqHyAEg+hCkASCFUHgDJh2oEAACAMKhGAAAAiBHCFAAAQACEKQAAgAAIUwCQBKg8AFJXRGHKzK4wsw/MrMLM7mpl+x1m9l7D7X0zqzOz3tEfFwDSE5UHQOoKG6bMLFtSkaQrJQ2XNMvMhjfdx90fcvcL3P0CSd+T9Ia7/zUG8wJAWqLyAEhdkZyZGiupwt13uftRSc9LmtbO/rMkPReN4QAgUxQVSbW1oa8AUkskYSpf0t4my5UN645jZidLukLSS21sv8XMSs2stLq6uqOzAgAAJJ1IwpS1sq6tps+pkt5q6yU+d1/q7gXuXpCXlxfpjAAAAEkrkjBVKem0JssDJX3axr4zxUt8AAAgg0QSpkokDTWzIWbWWaHAtLLlTmbWU9J4SX+I7ogAkJqoOwAyQ9gw5e61khZIWiepXNJv3b3MzOaa2dwmu06X9Iq7H4nNqACQWqg7ADJDTiQ7ufsaSWtarHuixfJyScujNRgApLrCwlCQou4ASG/m3ta15LFVUFDgpaWlCXluAACAjjCzLe5e0No2Pk4GAAAgAMIUAABAAIQpAACAAAhTANBBVB4AaIowBQAdROUBgKYIUwDQQYWFUnY2lQcAQqhGAAAACINqBAAAgBghTAEAAARAmAIAAAiAMAUADag8AHAiCFMA0IDKAwAngjAFAA2oPABwIqhGAAAACINqBAAAgBghTAEAAARAmAIAAAiAMAUgrVF3ACDWCFMA0hp1BwBijTAFIK1RdwAg1qhGAAAACINqBAAAgBghTAEAAARAmAIAAAiAMAUgJVF5ACBZEKYApCQqDwAkC8IUgJRE5QGAZEE1AgAAQBhUIwAAAMQIYQoAACAAwhQAAEAAhCkASYXKAwCphjAFIKlQeQAg1RCmACQVKg8ApBqqEQAAAMKgGgEAACBGCFMAAAABEKYAAAACIEwBiDnqDgCkM8IUgJij7gBAOosoTJnZFWb2gZlVmNldbewzwczeM7MyM3sjumMCSGXUHQBIZ2GrEcwsW9KHki6XVCmpRNIsd9/RZJ9ekv4k6Qp332Nmfd29qr3HpRoBAACkiqDVCGMlVbj7Lnc/Kul5SdNa7HONpBXuvkeSwgUpAACAdBFJmMqXtLfJcmXDuqbOlpRrZuvNbIuZXd/aA5nZLWZWamal1dXVJzYxAABAEokkTFkr61q+NpgjaYykyZImSbrXzM4+7k7uS929wN0L8vLyOjwsAABAsokkTFVKOq3J8kBJn7ayz1p3P+LuNZI2SBoVnREBJCsqDwAgsjBVImmomQ0xs86SZkpa2WKfP0i62MxyzOxkSRdJKo/uqACSDZUHABBBmHL3WkkLJK1TKCD91t3LzGyumc1t2Kdc0lpJ2yVtlvRLd38/dmMDSAZUHgBABNUIsUI1AgAASBVBqxEAAADQBsIUAABAAIQpAACAAAhTAI5D5QEARI4wBeA4VB4AQOQIUwCOQ+UBAESOagQAAIAwqEYAAACIEcIUAABAAIQpAACAAAhTQIag7gAAYoMwBWQI6g4AIDYIU0CGoO4AAGKDagQAAIAwqEYAAACIEcIUAABAAIQpAACAAAhTQIqj8gAAEoswBaQ4Kg8AILEIU0CKo/IAABKLagQAAIAwqEYAAACIEcIUAABAAIQpAACAAAhTQJKi8gAAUgNhCkhSVB4AQGogTAFJisoDAEgNVCMAAACEQTUCAABAjBCmAAAAAiBMAQAABECYAgAACIAwBcQR3VEAkH4IU0Ac0R0FAOmHMAXEEd1RAJB+6JkCAAAIg54pAACAGCFMAQAABECYAgAACIAwBUQBlQcAkLkIU0AUUHkAAJmLMAVEAZUHAJC5IgpTZnaFmX1gZhVmdlcr2yeY2SEze6/htjj6owLJq6hIqq0NfQUAZJaccDuYWbakIkmXS6qUVGJmK919R4tdN7r7lBjMCAAAkLQiOTM1VlKFu+9y96OSnpc0LbZjAQAApIZIwlS+pL1Nlisb1rU0zsy2mdl/mtl5rT2Qmd1iZqVmVlpdXX0C4wIAACSXSMKUtbKu5WfQbJU0yN1HSfo/kn7f2gO5+1J3L3D3gry8vA4NCsQbdQcAgEhEEqYqJZ3WZHmgpE+b7uDun7n74Ybv10jqZGZ9ojYlkADUHQAAIhFJmCqRNNTMhphZZ0kzJa1suoOZ9Tcza/h+bMPjHoz2sEA8UXcAAIhE2HfzuXutmS2QtE5StqRl7l5mZnMbtj8h6VuS/reZ1Ur6m6SZ7t7ypUAgpRQVUXUAAAjPEpV5CgoKvLS0NCHPDQAA0BFmtsXdC1rbRgM6AABAAIQpAACAAAhTyDhUHgAAookwhYxD5QEAIJoIU8g4VB4AAKKJd/MBAACEwbv5AAAAYoQwBQAAEABhCgAAIADCFNIGlQcAgEQgTCFtUHkAAEgEwhTSBpUHAIBEoBoBAAAgDKoRAAAAYoQwBQAAEABhCgAAIADCFJIadQcAgGRHmEJSo+4AAJDsCFNIatQdAACSHdUIAAAAYVCNAAAAECOEKQAAgAAIUwAAAAEQppAQVB4AANIFYQoJQeUBACBdEKaQEFQeAADSBdUIAAAAYVCNAAAAECOEKQAAgAAIUwAAAAEQphBVVB4AADINYQpRReUBACDTEKYQVVQeAAAyDdUIAAAAYVCNAAAAECOEKQAAgAAIUwAAAAEQphAWdQcAALSNMIWwqDsAAKBthCmERd0BAABtoxoBAAAgjMDVCGZ2hZl9YGYVZnZXO/tdaGZ1ZvatEx0WAAAglYQNU2aWLalI0pWShkuaZWbD29jvx5LWRXtIAACAZBXJmamxkircfZe7H5X0vKRprez3L5JeklQVxfkAAACSWiRhKl/S3ibLlQ3rGplZvqTpkp5o74HM7BYzKzWz0urq6o7Oiiij8gAAgOAiCVPWyrqWV63/XNIid69r74Hcfam7F7h7QV5eXoQjIlaoPAAAILhIwlSlpNOaLA+U9GmLfQokPW9muyV9S9K/m9k3ozEgYofKAwAAggtbjWBmOZI+lHSZpH2SSiRd4+5lbey/XNIqd3+xvcelGgEAAKSK9qoRcsLd2d1rzWyBQu/Sy5a0zN3LzGxuw/Z2r5MCAABIZ2HDlCS5+xpJa1qsazVEufuc4GMBAACkBj5OBgAAIADCVBqi8gAAgPghTKUhKg8AAIgfwlQaovIAAID4CVuNECtUIwAAgFTRXjUCZ6YAAAACIEwBAAAEQJgCAAAIgDCVIqg7AAAgORGmUgR1BwAAJCfCVIqg7gAAgORENQIAAEAYVCMAAADECGEKAAAgAMIUAABAAISpBKPyAACA1EaYSjAqDwAASG2EqQSj8gAAgNRGNQIAAEAYVCMAAADECGEKAAAgAMIUAABAAISpGKHyAACAzECYihEqDwAAyAyEqRih8gAAgMxANQIAAEAYVCMAAADECGEKAAAgAMIUAABAAISpDqDuAAAAtESY6gDqDgAAQEuEqQ6g7gAAALRENQIAAEAYVCMAAADECGEKAAAgAMIUAABAAIQpUXkAAABOHGFKVB4AAIATR5gSlQcAAODEUY0AAAAQBtUIAAAAMRJRmDKzK8zsAzOrMLO7Wtk+zcy2m9l7ZlZqZl+P/qgAAADJJyfcDmaWLalI0uWSKiWVmNlKd9/RZLfXJK10dzezkZJ+K+ncWAwMAACQTCI5MzVWUoW773L3o5KelzSt6Q7uftj/cfFVN0mJuRALAAAgziIJU/mS9jZZrmxY14yZTTeznZJWS7oxOuMFQ38UAACItUjClLWy7rgzT+7+srufK+mbkh5o9YHMbmm4pqq0urq6Q4OeCPqjAABArEUSpiolndZkeaCkT9va2d03SDrTzPq0sm2puxe4e0FeXl6Hh+0o+qMAAECsRRKmSiQNNbMhZtZZ0kxJK5vuYGZnmZk1fD9aUmdJB6M9bEcVFUm1taGvAAAAsRD23XzuXmtmCyStk5QtaZm7l5nZ3IbtT0i6WtL1ZnZM0t8kzfBEtYECAADEEQ3oAAAAYdCADgAAECOEKQAAgAAIUwAAAAEQpgAAAAIgTAEAAARAmAIAAAiAMAUAABAAYQoAACAAwhQAAEAAhCkAAIAACFMAAAABEKYAAAACSNgHHZtZtaRP4vBUfSTVxOF50HEcm+TG8UleHJvkxvFJXkGOzSB3z2ttQ8LCVLyYWWlbn/KMxOLYJDeOT/Li2CQ3jk/yitWx4WU+AACAAAhTAAAAAWRCmFqa6AHQJo5NcuP4JC+OTXLj+CSvmBybtL9mCgAAIJYy4cwUAABAzBCmAAAAAkiLMGVmV5jZB2ZWYWZ3tbLdzOyxhu3bzWx0IubMVBEcn2sbjst2M/uTmY1KxJyZKNyxabLfhWZWZ2bfiud8mS6S42NmE8zsPTMrM7M34j1jporgv2s9zeyPZrat4djckIg5M5GZLTOzKjN7v43t0c8E7p7SN0nZkj6SdIakzpK2SRreYp+rJP2nJJP0NUnvJHruTLlFeHz+SVJuw/dXcnyS59g02e//Sloj6VuJnjtTbhH+2+klaYek0xuW+yZ67ky4RXhs7pb044bv8yT9VVLnRM+eCTdJl0gaLen9NrZHPROkw5mpsZIq3H2Xux+V9LykaS32mSbpKQ/ZJKmXmZ0a70EzVNjj4+5/cvf/17C4SdLAOM+YqSL5tyNJ/yLpJUlV8RwOER2fayStcPc9kuTuHKP4iOTYuKRTzMwkdVcoTNXGd8zM5O4bFPp5tyXqmSAdwlS+pL1Nlisb1nV0H8RGR3/2Nyn0GwNiL+yxMbN8SdMlPRHHuRASyb+dsyXlmtl6M9tiZtfHbbrMFsmxeVzSMEmfSvqzpFvdvT4+4yGMqGeCnEDjJAdrZV3LvodI9kFsRPyzN7OJCoWpr8d0IvyPSI7NzyUtcve60C/YiKNIjk+OpDGSLpPUVdLbZrbJ3T+M9XAZLpJjM0nSe5IulXSmpFfNbKO7fxbj2RBe1DNBOoSpSkmnNVkeqNBvAh3dB7ER0c/ezEZK+qWkK939YJxmy3SRHJsCSc83BKk+kq4ys1p3/31cJsxskf63rcbdj0g6YmYbJI2SRJiKrUiOzQ2SfuShi3QqzOxjSedK2hyfEdGOqGeCdHiZr0TSUDMbYmadJc2UtLLFPislXd9wBf/XJB1y9/3xHjRDhT0+Zna6pBWSruM36rgKe2zcfYi7D3b3wZJelDSPIBU3kfy37Q+SLjazHDM7WdJFksrjPGcmiuTY7FHojKHMrJ+kcyTtiuuUaEvUM0HKn5ly91ozWyBpnULvsFjm7mVmNrdh+xMKvQvpKkkVkr5Q6DcGxEGEx2expK9I+veGMyC1zieux1yExwYJEsnxcfdyM1srabukekm/dPdW3w6O6Inw384Dkpab2Z8VellpkbvXJGzoDGJmz0maIKmPmVVKuk9SJyl2mYCPkwEAAAggHV7mAwAASBjCFAAAQACEKQAAgAAIUwAAAAEQpgAAAAIgTAEAAARAmAIAAAjg/wOpTIj28IK1hAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Note: If you've reset your runtime, this function won't work, \n",
        "# you'll have to rerun the cell above where it's instantiated.\n",
        "plot_predictions(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0ycBrxIec07"
      },
      "source": [
        "### 6.2 Building a PyTorch linear model\n",
        "\n",
        "We've got some data, now it's time to make a model.\n",
        "\n",
        "We'll create the same style of model as before except this time, instead of defining the weight and bias parameters of our model manually using `nn.Parameter()`, we'll use [`nn.Linear(in_features, out_features)`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) to do it for us.\n",
        "\n",
        "Where `in_features` is the number of dimensions your input data has and `out_features` is the number of dimensions you'd like it to be output to.\n",
        "\n",
        "In our case, both of these are `1` since our data has `1` input feature (`X`) per label (`y`).\n",
        "\n",
        "![comparison of nn.Parameter Linear Regression model and nn.Linear Linear Regression model](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-linear-regression-model-with-nn-Parameter-and-nn-Linear-compared.png)\n",
        "*Creating a linear regression model using `nn.Parameter` versus using `nn.Linear`. There are plenty more examples of where the `torch.nn` module has pre-built computations, including many popular and useful neural network layers.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iOwqtFqec08",
        "outputId": "f7aabd1d-55a7-4f1e-c9b9-9db73d178aef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(LinearRegressionModelV2(\n",
              "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              " ),\n",
              " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "              ('linear_layer.bias', tensor([0.8300]))]))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subclass nn.Module to make our model\n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use nn.Linear() for creating the model parameters\n",
        "        self.linear_layer = nn.Linear(in_features=1, \n",
        "                                      out_features=1)\n",
        "    \n",
        "    # Define the forward computation (input data x flows through nn.Linear())\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "# Set the manual seed when creating the model (this isn't always need but is used for demonstrative purposes, try commenting it out and seeing what happens)\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vLN2pPXNXUs"
      },
      "source": [
        "Notice the outputs of `model_1.state_dict()`, the `nn.Linear()` layer created a random `weight` and `bias` parameter for us.\n",
        "\n",
        "Now let's put our model on the GPU (if it's available).\n",
        "\n",
        "We can change the device our PyTorch objects are on using `.to(device)`.\n",
        "\n",
        "First let's check the model's current device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhCvYNpAec08",
        "outputId": "4d0d2c5f-4a9c-44a0-bda5-fd54d16cfa51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check model device\n",
        "next(model_1.parameters()).device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqalUGW5N93K"
      },
      "source": [
        "Wonderful, looks like the model's on the CPU by default.\n",
        "\n",
        "Let's change it to be on the GPU (if it's available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfTYec5Rec08",
        "outputId": "b0d331ba-56b9-4f18-f93d-de7965de41dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set model to GPU if it's availalble, otherwise it'll default to CPU\n",
        "model_1.to(device) # the device variable was set above to be \"cuda\" if available or \"cpu\" if not\n",
        "next(model_1.parameters()).device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHs0bL5_Oc1k"
      },
      "source": [
        "Nice! Because of our device agnostic code, the above cell will work regardless of whether a GPU is available or not.\n",
        "\n",
        "If you do have access to a CUDA-enabled GPU, you should see an output of something like:\n",
        "\n",
        "```\n",
        "device(type='cuda', index=0)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwTeP_vkec08"
      },
      "source": [
        "### 6.3 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPFOV3wUec09"
      },
      "source": [
        "Time to build a training and testing loop.\n",
        "\n",
        "First we'll need a loss function and an optimizer.\n",
        "\n",
        "Let's use the same functions we used earlier, `nn.L1Loss()` and `torch.optim.SGD()`.\n",
        "\n",
        "We'll have to pass the new model's parameters (`model.parameters()`) to the optimizer for it to adjust them during training. \n",
        "\n",
        "The learning rate of `0.1` worked well before too so let's use that again.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRgqFKrNec09"
      },
      "outputs": [],
      "source": [
        "# Create loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), # optimize newly created model's parameters\n",
        "                            lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxuBdoWRP2nU"
      },
      "source": [
        "Beautiful, loss function and optimizer ready, now let's train and evaluate our model using a training and testing loop.\n",
        "\n",
        "The only different thing we'll be doing in this step compared to the previous training loop is putting the data on the target `device`.\n",
        "\n",
        "We've already put our model on the target `device` using `model_1.to(device)`.\n",
        "\n",
        "And we can do the same with the data.\n",
        "\n",
        "That way if the model is on the GPU, the data is on the GPU (and vice versa).\n",
        "\n",
        "Let's step things up a notch this time and set `epochs=1000`.\n",
        "\n",
        "If you need a reminder of the PyTorch training loop steps, see below.\n",
        "\n",
        "<details>\n",
        "    <summary>PyTorch training loop steps</summary>\n",
        "    <ol>\n",
        "        <li><b>Forward pass</b> - The model goes through all of the training data once, performing its\n",
        "            <code>forward()</code> function\n",
        "            calculations (<code>model(x_train)</code>).\n",
        "        </li>\n",
        "        <li><b>Calculate the loss</b> - The model's outputs (predictions) are compared to the ground truth and evaluated\n",
        "            to see how\n",
        "            wrong they are (<code>loss = loss_fn(y_pred, y_train</code>).</li>\n",
        "        <li><b>Zero gradients</b> - The optimizers gradients are set to zero (they are accumulated by default) so they\n",
        "            can be\n",
        "            recalculated for the specific training step (<code>optimizer.zero_grad()</code>).</li>\n",
        "        <li><b>Perform backpropagation on the loss</b> - Computes the gradient of the loss with respect for every model\n",
        "            parameter to\n",
        "            be updated (each parameter\n",
        "            with <code>requires_grad=True</code>). This is known as <b>backpropagation</b>, hence \"backwards\"\n",
        "            (<code>loss.backward()</code>).</li>\n",
        "        <li><b>Step the optimizer (gradient descent)</b> - Update the parameters with <code>requires_grad=True</code>\n",
        "            with respect to the loss\n",
        "            gradients in order to improve them (<code>optimizer.step()</code>).</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDOHzX8lec09",
        "outputId": "23ee6dda-7145-463c-e684-d65ba6874757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Train loss: 0.5551779866218567 | Test loss: 0.5739762187004089\n",
            "Epoch: 100 | Train loss: 0.006215683650225401 | Test loss: 0.014086711220443249\n",
            "Epoch: 200 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882\n",
            "Epoch: 300 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882\n",
            "Epoch: 400 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882\n",
            "Epoch: 500 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882\n",
            "Epoch: 600 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882\n",
            "Epoch: 700 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882\n",
            "Epoch: 800 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882\n",
            "Epoch: 900 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs \n",
        "epochs = 1000 \n",
        "\n",
        "# Put data on the available device\n",
        "# Without this, error will happen (not all model/data on device)\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_1.train() # train mode is on by default after construction\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_1(X_train)\n",
        "\n",
        "    # 2. Calculate loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Step the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_1.eval() # put the model in evaluation mode for testing (inference)\n",
        "    # 1. Forward pass\n",
        "    with torch.inference_mode():\n",
        "        test_pred = model_1(X_test)\n",
        "    \n",
        "        # 2. Calculate the loss\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt-b2Y131flk"
      },
      "source": [
        "> **Note:** Due to the random nature of machine learning, you will likely get slightly different results (different loss and prediction values) depending on whether your model was trained on CPU or GPU. This is true even if you use the same random seed on either device. If the difference is large, you may want to look for errors, however, if it is small (ideally it is), you can ignore it.\n",
        "\n",
        "Nice! That loss looks pretty low.\n",
        "\n",
        "Let's check the parameters our model has learned and compare them to the original parameters we hard-coded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP_tFn5rec09",
        "outputId": "53b6c53a-1bab-4f13-e09a-c9473200af39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model learned the following values for weights and bias:\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6968]], device='cuda:0')),\n",
            "             ('linear_layer.bias', tensor([0.3025], device='cuda:0'))])\n",
            "\n",
            "And the original values for weights and bias are:\n",
            "weights: 0.7, bias: 0.3\n"
          ]
        }
      ],
      "source": [
        "# Find our model's learned parameters\n",
        "from pprint import pprint # pprint = pretty print, see: https://docs.python.org/3/library/pprint.html \n",
        "print(\"The model learned the following values for weights and bias:\")\n",
        "pprint(model_1.state_dict())\n",
        "print(\"\\nAnd the original values for weights and bias are:\")\n",
        "print(f\"weights: {weight}, bias: {bias}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDZo0vEU1_-1"
      },
      "source": [
        "Ho ho! Now that's pretty darn close to a perfect model.\n",
        "\n",
        "Remember though, in practice, it's rare that you'll know the perfect parameters ahead of time.\n",
        "\n",
        "And if you knew the parameters your model had to learn ahead of time, what would be the fun of machine learning?\n",
        "\n",
        "Plus, in many real-world machine learning problems, the number of parameters can well exceed tens of millions.\n",
        "\n",
        "I don't know about you but I'd rather write code for a computer to figure those out rather than doing it by hand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBR1qvqhec09"
      },
      "source": [
        "### 6.4 Making predictions\n",
        "\n",
        "Now we've got a trained model, let's turn on it's evaluation mode and make some predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksqG5N5Iec09",
        "outputId": "a0d4a51f-e1d9-4038-fd8a-0bbf4386f36a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8600],\n",
              "        [0.8739],\n",
              "        [0.8878],\n",
              "        [0.9018],\n",
              "        [0.9157],\n",
              "        [0.9296],\n",
              "        [0.9436],\n",
              "        [0.9575],\n",
              "        [0.9714],\n",
              "        [0.9854]], device='cuda:0')"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn model into evaluation mode\n",
        "model_1.eval()\n",
        "\n",
        "# Make predictions on the test data\n",
        "with torch.inference_mode():\n",
        "    y_preds = model_1(X_test)\n",
        "y_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtOoVnbi2ysL"
      },
      "source": [
        "If you're making predictions with data on the GPU, you might notice the output of the above has `device='cuda:0'` towards the end. That means the data is on CUDA device 0 (the first GPU your system has access to due to zero-indexing), if you end up using multiple GPUs in the future, this number may be higher. \n",
        "\n",
        "Now let's plot our model's predictions.\n",
        "\n",
        "> **Note:** Many data science libraries such as pandas, matplotlib and NumPy aren't capable of using data that is stored on GPU. So you might run into some issues when trying to use a function from one of these libraries with tensor data not stored on the CPU. To fix this, you can call [`.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html) on your target tensor to return a copy of your target tensor on the CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Z4dmfr2bec09",
        "outputId": "dd68d5a7-1733-4385-c1cb-7d7b44085813"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot_predictions(predictions=y_preds) # -> won't work... data not on CPU\n",
        "\n",
        "# Put data on the CPU and plot it\n",
        "plot_predictions(predictions=y_preds.cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxZa-5-Tec0-"
      },
      "source": [
        "Woah! Look at those red dots, they line up almost perfectly with the green dots. I guess the extra epochs helped.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8jCHl1gec0-"
      },
      "source": [
        "### 6.5 Saving and loading a model\n",
        "\n",
        "We're happy with our models predictions, so let's save it to file so it can be used later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcQo4JqL7eSU",
        "outputId": "e43ada0c-c074-4b50-9207-fa01581b1d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to: models/01_pytorch_workflow_model_1.pth\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory \n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path \n",
        "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dict \n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_1.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
        "           f=MODEL_SAVE_PATH) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk0rvpwV7slc"
      },
      "source": [
        "And just to make sure everything worked well, let's load it back in.\n",
        "\n",
        "We'll:\n",
        "* Create a new instance of the `LinearRegressionModelV2()` class\n",
        "* Load in the model state dict using `torch.nn.Module.load_state_dict()`\n",
        "* Send the new instance of the model to the target device (to ensure our code is device-agnostic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMnVHzf1ec0-",
        "outputId": "76f10046-cd42-4b39-a372-aa95227828e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model:\n",
            "LinearRegressionModelV2(\n",
            "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n",
            "Model on device:\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Instantiate a fresh instance of LinearRegressionModelV2\n",
        "loaded_model_1 = LinearRegressionModelV2()\n",
        "\n",
        "# Load model state dict \n",
        "loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "# Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)\n",
        "loaded_model_1.to(device)\n",
        "\n",
        "print(f\"Loaded model:\\n{loaded_model_1}\")\n",
        "print(f\"Model on device:\\n{next(loaded_model_1.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv6EMEx99LV2"
      },
      "source": [
        "Now we can evaluate the loaded model to see if its predictions line up with the predictions made prior to saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYODT7ONec0_",
        "outputId": "c8184cd1-595a-43e4-8155-89dcecc4d0b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True]], device='cuda:0')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate loaded model\n",
        "loaded_model_1.eval()\n",
        "with torch.inference_mode():\n",
        "    loaded_model_1_preds = loaded_model_1(X_test)\n",
        "y_preds == loaded_model_1_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M_kcRC89YrZ"
      },
      "source": [
        "# Ejemplo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfL9_NWpGZmp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#hiper parametros \n",
        "input_size = 1\n",
        "output_size = 1 \n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset manual con array Numpy \n",
        "\n",
        "x_train = np.array([[3.3], [4.4],[5.5],[6.71],[6.93],[4.168],[9.779],[6.182],[7.59],[2.167],[7.042],[10.792],[5.313],[7.997],[3.1]], dtype=np.float32)\n",
        "y_train = np.array([[1, 7], [2.76, 0], [2.09, 0], [3.19, 0], [1.694, 0], [1.563, 0], [3.366, 0], [2.596, 0], [2.53, 0], [1.221, 0], [2.827, 0], [3.465, 0], [1.65, 0], [2.904, 0], [1.3, 0]], dtype=np.float32)\n",
        "\n",
        "# definiendo el modelo de regresion inicial \n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "#perdida y optimizador \n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# entrenado el modelo \n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  inputs = torch.from_numpy(x_train)\n",
        "  targets = torch.from_numpy(y_train)\n",
        "  # forward adelantado \n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, targets)\n",
        "  #backward y optimizacion \n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    print('Epoch[{}/{}],loss{:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "  #visualizacion con matplotilb\n",
        "  predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
        "  plt.plot(x_train,y_train,'ro',label='original data')\n",
        "  plt.plot(x_train,predicted, label ='fiteted line')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  #guardar modelo \n",
        "  torch.save (model.state_dict(),'my_modelo.pkl')\n",
        "\n",
        "  #cargar modelo exixtente \n",
        "  model.load_state_dict(torch.load('my_modelo.pkl'))\n",
        "  \n",
        "\n"
      ]
    }
  ]
}